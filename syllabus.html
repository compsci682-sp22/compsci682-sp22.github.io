<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">
    
    <!-- HTML4 meta tags forcing no-caching -->
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" />
    <meta http-equiv="Pragma" content="no-cache" />
    <meta http-equiv="Expires" content="0" />

    <link rel="icon" href="/favicon.ico?">

    <title>COMPSCI 682 Neural Networks: A Modern Introduction</title>

    <!-- Bootstrap core CSS -->
    <link href="assets/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="assets/css/offcanvas.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <script src="assets/js/ie-emulation-modes-warning.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>
    <nav class="navbar navbar-fixed-top navbar-custom">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <!--<a class="navbar-brand" href="https://www.cics.umass.edu/">COMPSCI697L</a>-->
          <a class="navbar-brand" href="https://www.cics.umass.edu/"><img style="max-height:15px; margin-top: 1px;"
             src="/assets/fig/umasslogo2.png"></a>
          <!--<a class="navbar-brand" href="#">COMPSCI697L</a>-->
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li><a href="/index.html">Home</a></li>
            <li class="active"><a href="/syllabus.html">Lectures</a></li>
            <li><a href="/notes/">Notes</a></li>
            <li><a href="/assignments.html">Assignments</a></li>
            <li><a href="/projects/">Project</a></li>
          </ul>
        </div><!-- /.nav-collapse -->
      </div><!-- /.container -->
    </nav><!-- /.navbar -->

    <div class="container">
      <h2>COMPSCI 682 Neural Networks: A Modern Introduction</h2>
      <div class="panel panel-info">
        <div class="panel-heading">
          <h3 class="panel-title">Note</h3>
        </div>
        <div class="panel-body">
          <ul>
            <li>This is a tentative class outline and is subject to change throughout the semester. </li>
            <li>Every Monday the lectures for the week will be posted. The videos for the previous week will be taken down when new videos are posted, but the slides will remain available. The reason we take down the videos is so that people do keep up with the videos. </li>
            <li> One lecture is associated with Tuesday, and the other one with Thursday.</li>
          </ul>
        </div>
      </div>
        <div class="panel panel-default">
<table class="table">
  <tbody>
    <tr class="active">
      <th>Event Type</th><th class="footer-col-4">Date</th><th class="footer-col-3">Description</th><th>Video Lectures</th><th>Course Materials</th>
    </tr>
    <tr>
      <td>Lecture 1A,1B</td> <!-- Lecture 1A,1B -->
      <td>Tuesday, Jan. 25</td>
      <td>1A: Course Organization and Structure <br> 1B: Intro to Deep Learning, historical context.</td>
      <td>
        <a href="https://echo360.org/media/43e1d58c-7f2b-4635-8dd3-4ae20ab1d4b4/public">[Lecture 1A]</a><br>
        <a href="https://echo360.org/media/bb6068b2-43f1-4462-9cd1-ccbe0d9f04eb/public">[Lecture 1B]</a><br>
      </td>
      <td>
        <a href="https://docs.google.com/presentation/d/1-CWlOzg71bUc7ajCwQmBkzZf-lrY9jTCRs6vHkJbcxU/edit?usp=sharing">[slides]</a><br>
        <a href="https://docs.google.com/presentation/d/12iWhW3czweIIVE18Dcc77DqU9y4_006zs7MDNvs57vs/edit?usp=sharing">[slides]</a><br>
        <a href="notes/python-numpy-tutorial/">[python/numpy tutorial]</a><br>
        <a href="notes/jupyter-tutorial/">[jupyter tutorial]</a>
      </td>
    </tr>
    <!-- <tr class="info">
      <td>Optional Discussion</td>
      <td>Friday, Sept. 3</td>
      <td>No discussion section</td>
      <td>
      </td>
    </tr> -->
    <tr>
    <td>Lecture 2 </td> <!-- Lecture 2 -->
      <td>Thursday, Jan. 27</td>
       <td>Image classification and the data-driven approach <br> k-nearest neighbor <br> Linear classification</td>
      <!-- <td>To be announced</td> -->
      <td> <a href="https://echo360.org/media/dfc10f48-85a0-4bed-9caf-7d8361a01cfc/public">[Lecture 2]</a></td>
      <td>
        <a href="https://docs.google.com/presentation/d/1zqU2vrqCCsd2cLpOG0ZHI8Lhe09wtmcHriyOf7Zn7JA/edit?usp=sharing">[slides]</a><br>
        <a href="notes/classification/">[image classification notes]</a><br>
        <a href="notes/linear-classify/">[linear classification notes]</a><br>
      </td> 
    </tr>
      <tr class="success">
    <td>Optional Zoom Discussion</td>
    <td>Monday, Jan. 31 <br> Session 1: 9:00AM - 9:45AM EST <br> Session 2: 4:00PM - 4:45PM EST</td>
    <td>Python setup, Google Colab, and the basics of Python</td>
        <td></td>
    <td>
    </td>
  </tr>
    
    <!-- Lecture 3 -->
    <tr>
    <td>Lecture 3</td> 
    <td>Tuesday, Feb. 1</td>
    <td>Loss Functions <br> Optimization</td>
      <td> <a href="https://echo360.org/media/cdf93da0-eca5-4779-9a0f-f3a82c802be2/public">[Lecture 3]</a> <br>Note: Lecture starts from time stamp [4:45]. Part of the video before that is not relevant for the current semester.</td>
    <td>
      <a href="https://docs.google.com/presentation/d/1Y-a_PJKDodaBJ5QgRCC-h0jOpQ_zvQUkP905giS1lT8/edit?usp=sharing">[slides]</a><br>
    </td>
  </tr>  
    
     <!-- Lecture 4 -->
  <tr>
    <td>Lecture 4</td> 
    <td>Thursday, Feb. 3</td>
    <td>
        Backpropagation &amp; Neural Networks I
    </td>
    <td> <a href="https://echo360.org/media/082b7978-a62f-4db1-8c9a-55c2a9aa5972/public">[Lecture 4]</a></td>
    <td>
      <a href="https://docs.google.com/presentation/d/1SaCuYERHM0y7xsjPqG5ptAWYx2xiYnoe0oKTSlRVkZk/edit?usp=sharing">[slides]</a><br>
      <a href="notes/optimization-2/">[backprop notes]</a><br>
      <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">[Efficient BackProp]</a> (optional)<br>
      related: <a href="http://colah.github.io/posts/2015-08-Backprop/">[1]</a>, <a href="http://neuralnetworksanddeeplearning.com/chap2.html">[2]</a>, <a href="https://www.youtube.com/watch?v=q0pm3BrIUFo">[3]</a> (optional)
    </td>
  </tr>
    
        <!-- Lecture 5 -->
  <tr>
    <td>Lecture 5</td> 
    <td>Tuesday, Feb. 8</td>
    <td>
        Neural Networks II<br>
        Higher-level representations, image features<br>
        Vector, Matrix, and Tensor Derivatives
    </td>
    <td> <a href="https://echo360.org/section/4c12d9e4-0125-4c9b-87a3-87671e8fb279/home">[Lecture 5]</a><br>Note: The help session for the Chain rule will be on Monday, February 14, not on Friday, as it says in the video.</td>
    <td>
      <a href="https://docs.google.com/presentation/d/1cnPe-Ar-t549Jsb1PU7UNXUDcmj8JOiOoSu7TefYSQc/edit?usp=sharing">[slides]</a><br>
      handout 1: <a href="/docs/vecDerivs.pdf">Vector, Matrix, and Tensor Derivatives</a><br>
      handout 2: <a href="http://cs231n.stanford.edu/handouts/derivatives.pdf">Derivatives, Backpropagation, and Vectorization</a><br>
      <a href="http://www.nature.com/nature/journal/v521/n7553/full/nature14539.html">Deep Learning [Nature]</a> (optional)
    </td>
  </tr>
    
   <!-- Lecture 6 -->
  <tr>
    <td>Lecture 6</td> 
    <td>Thursday, Feb. 10</td>
    <td>
        Neural Networks III <br>
        Training Neural Networks I <br>
        Activation Functions
    </td>
    <td> <a href="https://echo360.org/section/4c12d9e4-0125-4c9b-87a3-87671e8fb279/home">[Lecture 6]</a><br>Note:Please ignore the “Logistics” about Assignment 1 mentioned in the video, as they pertain to last semester.</td>
    <td>
        <a href="https://docs.google.com/presentation/d/1uU2a26196zytG1o0wIzoLBRMJFBm8WFL00QPLmzwkLQ/edit?usp=sharing">[slides]</a><br> 
        <a href="notes/neural-networks-1/">[Neural Nets notes 1]</a>
        tips/tricks:
        <a href="http://research.microsoft.com/pubs/192769/tricks-2012.pdf">[1]</a>,
        <a href="http://arxiv.org/pdf/1206.5533v2.pdf">[2]</a> (optional)
        <br>
    </td>
  </tr>
    
<tr class="success">
    <td>Optional Zoom Discussion</td>
    <td>Monday, Feb. 14 <br> Session 1: 8:00AM - 8:45AM EST <br> Session 2: 2:00PM - 2:45PM EST</td>
    <td>Reviewing the chain rule, applying the chain rule to vectors</td>
        <td></td>
    <td>
    </td>
</tr>
    
        <!-- Lecture 7 -->
  <tr>
    <td>Lecture 7</td> 
    <td>Tuesday, Feb. 15</td>
    <td>
        Training Neural Networks II <br>
        weight initialization, batch normalization
    </td>
    <td> <a href="https://echo360.org/section/4c12d9e4-0125-4c9b-87a3-87671e8fb279/home">[Lecture 7]</a><br>Note: Lecture starts from [ 3:02 ]. Discussion regarding projects from [ 3:02 - 22:47 ] is the same this semester. However the dates do not apply.</td>
    <td>
      <a href="https://docs.google.com/presentation/d/1tmN88iLh0tLRsyZPpb7DOUjxQ5P04DMPQcCzu3NcC0E/edit?usp=sharing">[slides]</a><br>
      <a href="notes/neural-networks-2/">[Neural Nets notes 2]</a><br> 
      <a href="https://arxiv.org/abs/1502.03167">[Batch Norm]</a><br>
      <a href="https://drive.google.com/file/d/16UZc7_uDhhj-hmmGt9wz0bbqhbpXSWWA/view?usp=sharing">Copula Normalization</a> (optional)
    </td>
  </tr>
    
        <!-- Lecture 8 -->
  <tr>
    <td>Lecture 8</td> 
    <td>Thursday, Feb. 17</td>
    <td>
        Training Neural Network III: <br>
        babysitting the learning process, hyperparameter optimization
    </td>
    <td> <a href="https://echo360.org/section/4c12d9e4-0125-4c9b-87a3-87671e8fb279/home">[Lecture 8]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1WRQZPjN8cQ8OhFR5Sw8tu5WkXqwZ1Sy7yduYFR7BWfE/edit?usp=sharing">[slides]</a><br> 
        <a href="https://arxiv.org/abs/1206.5533">[Bengio 2012]</a> (optional)
    </td>
  </tr>
    
    
        <!-- Lecture 9 -->
  <tr>
    <td>Lecture 9</td> 
    <td>Thursday, Feb. 24</td>
    <td>
        Training Neural Network IV: <br>
        model ensembles, dropout
    </td>
    <td> <a href="https://echo360.org/section/4c12d9e4-0125-4c9b-87a3-87671e8fb279/home">[Lecture 9]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1SPk-x43KFbKW7eQXgAm48HTyJwC0-1gO5FN3qfrIaW4/edit?usp=sharing">[slides]</a><br>
        <a href="notes/neural-networks-3/">[Neural Nets notes 3]</a><br>
        <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf">LeNet</a> (optional)<br>
    </td>
  </tr>

        <!-- Lecture 10 -->
  <tr>
    <td>Lecture 10</td> 
    <td>Tuesday, Mar. 1</td>
    <td>
        DropOut... continued
    </td>
    <td> <a href="https://echo360.org/lesson/78d8e905-774f-4835-82cb-cb17dc930f45/classroom?focus=Video#sortDirection=desc">[Lecture 10]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1R3RzjwhkVKT3UZQSnYDPb48jEuwLrw4r/edit?usp=sharing&ouid=108586882201234844889&rtpof=true&sd=true">[slides]</a><br>
    </td>
  </tr>

        <!-- Lecture 11 -->
  <tr>
    <td>Lecture 11 (a)</td> 
    <td>Thursday, Mar. 3</td>
    <td>
        Convolutional Neural Networks
    </td>
    <td> <a href="https://echo360.org/lesson/5687f220-7f77-4942-a32c-e42832632a6a/classroom#sortDirection=desc">[Lecture 11 with slides]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1AnBsvkDZjTgiSDQnNA0l5O0JxVYjHkCX/edit?usp=sharing&ouid=108586882201234844889&rtpof=true&sd=true">[slides]</a><br>
    </td>
  </tr>

  <tr>
    <td>Lecture 11b</td> 
    <td>Tuesday, Mar. 8</td>
    <td>
        Convolutional Neural Networks... continued
    </td>
    <td> <a href="https://echo360.org/lesson/31b39d40-782e-4a0a-b959-26e53fac0e21/classroom#sortDirection=desc">[Lecture 11b]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1AnBsvkDZjTgiSDQnNA0l5O0JxVYjHkCX/edit?usp=sharing&ouid=108586882201234844889&rtpof=true&sd=true">[slides]</a><br>
    </td>
  </tr>

  <tr>
    <td>Lecture 11c</td> 
    <td>Tuesday, Mar. 8</td>
    <td>
        Convolutional Neural Networks... continued
    </td>
    <td> <a href="https://echo360.org/lesson/b08fad57-7abc-4b98-b412-eebde2b4bf2f/classroom#sortDirection=desc">[Lecture 11c]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1AnBsvkDZjTgiSDQnNA0l5O0JxVYjHkCX/edit?usp=sharing&ouid=108586882201234844889&rtpof=true&sd=true">[slides]</a><br>
    </td>
  </tr>
    
    
           <!-- Lecture 11 (b) and (c) -->
  <tr>
    <td>Lecture 11 <br>(b) (c)</td> 
    <td>Tuesday, Mar. 8</td>
    <td>
        Convolutional Neural Networks (continued)
    </td>
    <td> <a href="https://echo360.org/section/4c12d9e4-0125-4c9b-87a3-87671e8fb279/home">[Lecture 11 (b) and (c)]</a></td>
    <td>
      <a href="https://docs.google.com/presentation/d/1AnBsvkDZjTgiSDQnNA0l5O0JxVYjHkCX/edit?usp=sharing&ouid=108586882201234844889&rtpof=true&sd=true">[slides]</a><br>
    </td>
  </tr>
    
    <tr class="success">
    <td>Optional Zoom Discussion</td>
    <td>Wednesday, Mar. 23 <br> Session 1: 9:00AM - 9:45AM EST <br> Session 2: 4:00PM - 5:00PM EST</td>
    <td>Batch normalization</td>
        <td></td>
    <td>
    </td>
  </tr>
    
    
          <!-- Lecture 12(a) -->
  <tr>
    <td>Lecture 12 (a)</td> 
    <td>Tuesday, Mar. 22</td>
    <td>
        ConvNets for spatial localization<br>
      Object detection
    </td>
    <td> <a href="https://echo360.org/section/4c12d9e4-0125-4c9b-87a3-87671e8fb279/home">[Lecture 12 (a)]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1CkLOU9IjoY9O7Tz-hXJ9vGNghim0n8S8s3P5H230eyA/edit?usp=sharing">[slides]</a><br>
        <a href="https://arxiv.org/abs/1512.03385">ResNet</a> (optional)<br>
        <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf">FCN</a> (optional)<br>
    </td>
  </tr>
    
             <!-- Lecture 12(b) -->
  <tr>
    <td>Lecture 12 (b)</td> 
    <td>Thursday, Mar. 24</td>
    <td>
        ConvNets for spatial localization<br>
      Object detection (continued)
    </td>
    <td> <a href="https://echo360.org/section/4c12d9e4-0125-4c9b-87a3-87671e8fb279/home">[Lecture 12 (b)]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1CkLOU9IjoY9O7Tz-hXJ9vGNghim0n8S8s3P5H230eyA/edit?usp=sharing">[slides]</a><br>
     
    </td>
  </tr>



          <!-- Lecture 14(a) -->
  <tr>
    <td>Lecture 14 (a)</td> 
    <td>Tuesday, Mar. 29</td>
    <td>
        Understanding and visualizing Convolutional Neural Networks, Plus Self-supervision 
    </td>
    <td> <a href="https://echo360.org/lesson/6d7beb99-a2f8-4ae3-8ec8-761a3c65eb06/classroom?focus=Video#sortDirection=desc">[Lecture 14 (a)]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1z5Zf315qVwYgUNN3pvQgplnAF7Ck5VUlJyH_9qwK8HU/edit?usp=sharing">[slides]</a><br>
        <a href="https://compsci682-fa21.github.io/notes/understanding-cnn/">Visualization notes</a> <br>
    </td>
  </tr>
    
             <!-- Lecture 14(b) -->
  <tr>
    <td>Lecture 14 (b)</td> 
    <td>Thursday, Mar. 31</td>
    <td>
        Understanding and visualizing Convolutional Neural Networks, Plus Self-supervision (continued)
    </td>
    <td> <a href="https://echo360.org/lesson/224c59a9-28b3-43cc-aa9f-f7afa7f9b69c/classroom?focus=Video#sortDirection=desc">[Lecture 14 (b)]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1z5Zf315qVwYgUNN3pvQgplnAF7Ck5VUlJyH_9qwK8HU/edit?usp=sharing">[slides]</a><br>
     
    </td>
  </tr>
    
               <!-- Lecture 15 -->
  <tr>
    <td>Lecture 15</td> 
    <td>Tuesday, April 5</td>
    <td>
        Neural Texture Synthesis and Style Transfer<br>
        Creating Adversarial Examples
    </td>
    <td> <a href="https://echo360.org/section/4c12d9e4-0125-4c9b-87a3-87671e8fb279/home">[Lecture 15]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1vY28rs4V--MeoaT4d2T6b5FTQhy7ddQzPR-MVmR5-9E/edit?usp=sharing">[slides]</a><br>
        <a href="https://docs.google.com/presentation/d/1NSERi2RaxYQeUPW-P1JFfVbUcZxVOx9Ioael0dZHQa8/edit?usp=sharing">[slides]</a><br>
     
    </td>
  </tr>
    
               <!-- Lecture 16 -->
  <tr>
    <td>Lecture 16</td> 
    <td>Thursday, April 7</td>
    <td>
        Generative Adversarial Networks
    </td>
    <td> <a href="https://echo360.org/section/4c12d9e4-0125-4c9b-87a3-87671e8fb279/home">[Lecture 16]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1mCqNieQTz4AaqjNBfb2kUyGgMb3ZBYZbNf0cjmtoFL8/edit?usp=sharing">[slides]</a><br>
      <a href="https://www.youtube.com/watch?v=kSLJriaOumA">[Style-GAN]</a><br>
      <a href="https://www.youtube.com/watch?v=0zaGYLPj4Kk">[Alias-Free GAN]</a>
     
    </td>
  </tr>
    
                 <!-- Lecture 16 (RNN) -->
  <tr>
    <td>Lecture 16(RNN)</td> 
    <td>Tuesday, April 12</td>
    <td>
        Recurrent Neural Networks
    </td>
    <td> <a href="https://echo360.org/section/4c12d9e4-0125-4c9b-87a3-87671e8fb279/home">[Lecture 16: RNN ]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1lD_rtt-CW70z9efNsDS-eRzKfCOZchMV0N0KRvxnIQk/edit?usp=sharing">[slides]</a><br>
       <a href="http://www.deeplearningbook.org/contents/rnn.html">DL book RNN chapter</a> (optional)<br>
      <a href="https://gist.github.com/karpathy/d4dee566867f8291f086">min-char-rnn</a>, <a href="https://github.com/karpathy/char-rnn">char-rnn</a>, <a href="https://github.com/karpathy/neuraltalk2">neuraltalk2</a><br>
      <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of RNN</a> (optional) <br>
      <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a> (optional)
    </td>
  </tr>
    
                    <!-- Lecture 16 (RNN) -->
  <tr>
    <td>Lecture 16(RNN)(2)</td> 
    <td>Thursday, April 14</td>
    <td>
        Recurrent Neural Networks (continued)
    </td>
    <td> <a href="https://echo360.org/section/4c12d9e4-0125-4c9b-87a3-87671e8fb279/home">[Lecture 16: RNN (continued)]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1lD_rtt-CW70z9efNsDS-eRzKfCOZchMV0N0KRvxnIQk/edit?usp=sharing">[slides]</a><br>
    </td>
  </tr>
    
                     <!-- Lecture 15 revisited -->
  <tr>
    <td>Lecture </td> 
    <td>Tuesday, April 19</td>
    <td>
        Exam Review and Revisiting Neural Texture Synthesis and Style Transfer
    </td>
    <td> <a href="https://echo360.org/section/4c12d9e4-0125-4c9b-87a3-87671e8fb279/home">[Lecture 15 Revisited]</a></td>
  </tr>
    
                       <!-- Lecture 17 -->
  <tr>
    <td>Lecture 17 </td> 
    <td>Thursday, April 21</td>
    <td>
        Word Embeddings
    </td>
    <td> <a href="https://echo360.org/section/4c12d9e4-0125-4c9b-87a3-87671e8fb279/home">[Lecture 17: Word Embeddings]</a></td>
    <td>
        <a href="https://docs.google.com/presentation/d/1I4Ep7lhGTEtUc6pe5ALTFaoONkxhrEPjrsal7Uj74Uk/edit?usp=sharing">[slides]</a><br>
    </td>
  </tr>
    
    
    <tr>
    <td>Midterm </td> 
    <td>Tuesday, April 26</td>
    <td>
        Mid-Term Review
    </td>
    <td></td>
    <td>
        <a href="https://github.com/compsci682-sp22/compsci682-sp22.github.io/raw/main/682_Midterm_Review_Fall_2021.pdf">[Review]</a><br>
    </td>
  </tr>
    
    
    
    
  </tbody></table>
</div>

 
    
   

    
<!--   <tr class="success">
    <td>Optional Discussion</td>
    <td>TBD</td>
    <td>Reviewing the chain rule, applying the chain rule to vectors</td>
    <td><a href="https://docs.google.com/presentation/d/1LpA3EYyTtb9GlqEp1VFqsRQbdwQhG_8m/edit?usp=sharing&ouid=109406443820614506826&rtpof=true&sd=true">[slides]</a></td>
  </tr> -->
    

    

    
<!--   <tr class="success">
    <td>Optional Discussion</td>
    <td>TBD</td>
    <td>Vector, Matrix, and Tensor Derivatives</td>
    <td>
    </td>
  </tr> -->
    

    

    
    <!-- Lecture 10 -->
<!--   <tr> 
    <td>Lecture</td> 
    <td>TBD</td>
    <td>
        DropOut... continued
    </td>
    <td>
        <a href="https://docs.google.com/presentation/d/1mGJ9E6K2zhvM0m94hxtq_PqjTlErUxEi8j5Mm-aBug0/edit?usp=sharing">[slides]</a><br>
    </td>
  </tr> -->
    
    <!-- Lecture 11 -->
<!--   <tr>
    <td>Lecture</td>  
    <td>TBD</td>
    <td>
        Convolutional Neural Networks
    </td>
    <td>
        <a href="https://docs.google.com/presentation/d/1U2ijqAYtgQf8yG8swZhuAJFTSqRf7kSl8Pj4ZxHndLk/edit?usp=sharing">[slides]</a>
    </td>
  </tr> -->
    
<!--   <tr class="success">
    <td>Optional Discussion</td>
    <td>Friday, Oct. 8</td>
    <td>Batch normalization</td>
    <td>
    </td>
  </tr>   -->
    
    <!-- Lecture 12 -->
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td>  
    <td>
      ConvNets for spatial localization<br>
      Object detection
    </td>
    <td>
        <a href="https://docs.google.com/presentation/d/1LUVaGef1fglRqob3hkWIn899_Ueczx6WUv6j35ByDpc/edit?usp=sharing">[slides]</a><br>
        <a href="https://arxiv.org/abs/1512.03385">ResNet</a> (optional)<br>
        <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf">FCN</a> (optional)<br>
        <a href="http://cs231n.stanford.edu/2017/reports.html">[Stanford cs231n project reports: spring 2017]</a><br>
        <a href="http://cs231n.stanford.edu/2016/reports.html">[Stanford cs231n project reports: winter 2016]</a><br>
        <a href="http://cs231n.stanford.edu/2015/reports.html">[Stanford cs231n project reports: winter 2015</a>
    </td>
  </tr> -->
    
    <!-- Lecture 13 -->
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td>  
    <td>
      ConvNets for spatial localization<br>
      Object detection... continued
    </td>
    <td>
      
    </td>
  </tr> -->
    
    <!-- Lecture 14 -->
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td>  
    <td>
      Object detection... continued
    </td>
    <td>
      <a href="https://ezyang.github.io/convolution-visualizer/index.html">A tool to visualize convolutions</a>
    </td>
  </tr> -->
    
    <!-- Lecture 14 cont -->
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td> 
    <td>
      Understanding and visualizing Convolutional Neural Networks... continued<br>
    </td>
    <td>
      <a href="https://docs.google.com/presentation/d/1Va3fa3vPGPrHpqO9ToiMNROtJ-ACyyaIHlYnoL97En4/edit?usp=sharing">[slides]</a><br>
      <a href="notes/understanding-cnn/">[visualization notes]</a><br>
      
    </td>
  </tr> -->
    
  <!-- <tr class="success">
    <td>Optional Discussion</td>
    <td>Friday, Apr. 6</td>
    <td>Go through midterm problems</td>
    <td>
    </td>
  </tr> -->
    
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td>
    <td>
      Backprop into image: Visualizations, deep dream
    </td>
    <td>
      
    </td>
  </tr> -->
    
    <!-- Lecture 15/16 -->
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td> 
    <td>
      Neural Texture Synthesis and Style Transfer<br>
      Creating Adversarial Examples
    </td>
    <td>
      <a href="https://docs.google.com/presentation/d/1wXgv4a12IxZKu2ZcibSBk_y-pqqfWZ0xKgLHFnVH6uI/edit?usp=sharing">[slides]</a><br>
      <a href="https://docs.google.com/presentation/d/1Ff_s5QRb-X5HIdsbH9CfCUaVGUIsBQo1F7yBoglvuiY/edit?usp=sharing">[slides]</a>
    </td>
  </tr> -->
    
    
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td>
    <td>
      Generative Adversarial Networks
    </td>
    <td>
      <a href="https://docs.google.com/presentation/d/1DxDCbVU7HrzPTUGZQdMCMpPnRiJPIKNNLLtjOc67oXE/edit?usp=sharing">[slides]</a><br>
      <a href="https://www.youtube.com/watch?v=kSLJriaOumA">[Style-GAN]</a><br>
      <a href="https://www.youtube.com/watch?v=0zaGYLPj4Kk">[Alias-Free GAN]</a>
    </td>
  </tr> -->
    
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td>
    <td>
      Recurrent Neural Networks<br>
      Long Short Term Memory (LSTM)
    </td>
    <td>
      <a href="https://docs.google.com/presentation/d/1bsoVduW8a9Hs-T684gnzSkU97nfMAYowu-2GES3aaCE/edit?usp=sharing">[slides]</a><br>
      <a href="http://www.deeplearningbook.org/contents/rnn.html">DL book RNN chapter</a> (optional)<br>
      <a href="https://gist.github.com/karpathy/d4dee566867f8291f086">min-char-rnn</a>, <a href="https://github.com/karpathy/char-rnn">char-rnn</a>, <a href="https://github.com/karpathy/neuraltalk2">neuraltalk2</a><br>
      <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of RNN</a> (optional) <br>
      <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a> (optional)
    </td>
  </tr> -->
    
<!--   <tr class="success">
    <td>Optional Discussion</td>
    <td>Friday, Nov. 5</td>
    <td>Getting started with Project and Milestone Expectations</td>
    <td>
    </td>
  </tr> -->
    
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td>
    <td>
      RNN's: continued
    </td>
    <td>
    </td>
  </tr> -->
    
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td>
    <td>
      No class
    </td>
    <td></td>
  </tr> -->
    
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td>
    <td>
      Exam Review
    </td>
    <td>
    </td>
  </tr> -->
    
<!--   <tr class="danger">
    <td>Mid-Term</td>
    <td>TBD</td>
    <td>Midterm to be held during regular lecture time</td>
    <td></td>
  </tr> -->
    
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td>
    <td>
      Do word embeddings, ElMO? Attention and Self-Attention in NLP Transformers
    </td>
    <td>
      <a href="https://docs.google.com/presentation/d/12GFQqJmrfZ29beWLgZsGq4lzhVM0K6umEBvyyWjEUxQ/edit?usp=sharing">[slides]</a><br>
      <a href="notes/682_Midterm_Review_Fall_2021.pdf">[review sheet]</a><br>
    </td>
  </tr> -->
    
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td>
    <td>
      No class
    </td>
    <td>
    </td>
  </tr> -->
    
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td>
    <td>
      Guest Lecture on Transformers by Andrew Drozdov
    </td>
    <td>
      <a href="notes/cs682-transformers.pdf">[Slides]</a><br>
    </td>
  </tr> -->
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td>
    <td>
      TBD
    </td>
    <td>
    </td>
  </tr> -->
<!--   <tr>
    <td>Lecture</td>
    <td>TBD</td>
    <td>
      Last lecture
    </td>
    <td>
    </td>
  </tr> -->
    
<!-- </tbody></table>
</div> -->

    </div><!--/.container-->

    <footer class="site-footer">
      <div class="wrap">
        <div class="footer-col-1 column">
          <ul>
            <li><a href="https://github.com/compsci682-fa21">
              <span class="icon github">
                <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                   viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                  <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                  c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                  c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                  c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                  C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                  c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                  c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                  c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                  c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>
              <span class="username">compsci682-sp22</span>
            </a>
            </li>
            <!-- <li>
              <a href="mailto:compsci682@gmail.com">compsci682@gmail.com</a>
            </li> -->
          </ul>
        </div>
        <div class="footer-col-2 column">

        </div>

        <div class="footer-col-3 column">

        </div>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="assets/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="assets/js/ie10-viewport-bug-workaround.js"></script>
    <script src="assets/js/offcanvas.js"></script>
  </body>
</html>
